---
layout: project 
title: Network Embedding
description: Network embedding encodes all vertices in a network as a set of numerical vectors in accordance with it’s local and global structures.
image: /img/project_imgs/ne/networkembedding.png
people:
  - gweiwei
  - wlei
  - zjiang

---



# Catalog

[Introduction](#pos1)

[Reference](#pos2)


[Current projects](#pos3)
* [The Hidden Flow Structure and Metric Space under Random Walk based Network Embedding Algorithms](#pos31)
* [Input Output Network](#pos32)
	- [Purpose](#pos321)
	- [Method](#pos322)
	- [Results](#pos323)

<div id="pos1"></div>
# Introduction

Network embedding which encodes all vertices in a network as a set of numerical vectors in accordance with it’s local and global structures, has drawn widespread attention. Network embedding not only learns significant features of a network, such as the clustering and linking prediction but also learns the latent vector representation of the nodes which provides theoretical support for a variety of applications, such as visualization, node classification, and recommendation. 

In the past decade, there has been a lot of research in the field of graph embedding, with a focus on designing new embedding algorithms. More recently, researchers pushed forward scalable embedding algorithms that can be applied on graphs with millions of nodes and edges. In the following, we provide historical context about the research progress in this domain, then propose a taxonomy of graph embedding techniques  covering factorization methods, random walk techniques, deep learning , and other miscellaneous strategies.


<div id="pos2"></div>
# Reference

- D. Wang, P. Cui, and W. Zhu, “Structural deep network em-bedding,” in Proceedings of the 22nd International Conference on Knowledge Discovery and Data Mining. ACM, 2016, pp. 1225–1234.

- S. Cao, W. Lu, and Q. Xu, : Learning graph representations with global structural information in Proceedings of the 24th ACM International on Conference on Information and Knowledge Manage-ment. ACM, 2015.

- B. Perozzi, R. Al-Rfou, and S. Skiena, Deepwalk: Online learning of social representations, in Proceedings 20th international confer-ence on Knowledge discovery and data mining, 2014.

- A. Grover and J. Leskovec, Node2vec: Scalable feature learning for networks? In Proceedings of the 22nd International Conference on Knowledge Discovery and Data Mining. ACM, 2016.

- S. Cao, W. Lu, and Q. Xu, “Deep neural networks for learning graph representations,” in Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence. AAAI Press, 2016, pp. 1145–1152.


<div id="pos3"></div>
# Current projects

<div id="pos31"></div>
## The Hidden Flow Structure and Metric Space under Random Walk based Network Embedding Algorithms


Network embedding which encodes all vertices in a network as a set of numerical vectors in accordance with the networks’ local and global structures. Recently, several algorithms based on random walks such as deepwalk and node2vec have drawn much attention for their high efficiency and accuracy in node classification however there is still a lack of theoretical explanation, and the transparency of those algorithms has been doubted. Here, we propose FGE algorithm to uncover the underlying flow structure and its hidden metric space of the random walk based embedding algorithms. We show that the essence of embedding is the latent metric structure defined on the open-flow network. This discovery not only deepens our understanding of random walk based embedding algorithms but also helps in finding new potential applications in network embedding.

To build a connection between language and network, a random walk needs to be implemented on the network such that the node sequences generated by random walks are treated as sentences in which nodes resemble words. To reveal the flow structure behind a random walk strategy, we construct an open-flow network model in accordance with the random walk strategies. An open-flow network is a special directed weighted network in which the nodes are identical to those of the original network, and the weighted edges represent the actual fluxes realized by a large number of random walks. Figure 1 illustrates how the different open-flow networks are constructed for a single background binary network with deepwalk in the upper panel and node2vec in the lower panel.The combination of flow distance and the manifold learning method Multi-Dimensional Scaling is named as Flow-based Geometric Embedding (FGE).


<div align="center">
   <img src="/img/project_imgs/ne/fig1.png" height="70%" width="70%" />
   <div align="center" style="padding-bottom:20px">Fig.1. An example flow network including 7 nodes. (A) is the flux matrix F of the sampled network under condition C1 (p = 1, q = 1) . (B) shows the flow distances among all nodes, where infinity means that there is no connected path from i to j. (C)is the sampled random walk sequences. (D) shows the process of building an open flow network. deepwalk, node2vec and other random walks based algorithms.</div>
</div>


<div align="center">
   <img src="/img/project_imgs/ne/fig2.jpg" height="70%" width="70%" />
   <div align="center" style="padding-bottom:20px">Fig.2. The embedding of Karate Graph. The visualization results were generated by node2vec and FGE algorithms with label colors reflecting clustering results and node shapes indicating different embedding methods.</div>
</div>

1. We notice that the open flow network model can be used to reflect the flow structure behind different random walk strategies. As shown in table 1
2. We discover that there is a high correlation between the flow distance and the euclidean distance calculated by the embedding results of node2vec algorithm for any node pair, therefore, the embedding results of FGE and node2vec are highly correlated compared to other known embedding algorithms. As shown in table 2
3. We infer that there is a hidden metric structure in the embedding vector space, and this metric structure can be used for clustering and ranking nodes. As shown in Figure 2





<br/>
<br/>
<br/>
<br/>
<br/>

<hr>

<div id="pos32"></div>
# Input Output Network


## Background
The main content of input-output analysis is comprehending the technical and economic relationship between the sectors and quantitatively describing it is is an emphatic issue in the region economy research. However, few studies put effort into extracting the macro-level characteristics from the microscopic connections between these sectors and quantitatively comparing two economies from their structures.

<div id="pos321"></div>
## Purpose
We propose a network-based approach to treat industrial system as an open flow network where source and sink node are considered as environment to depict the influence of final demand and value-added. This new framework allows us to define a new distance(flow distance) by which we can capture information of directly consumed relationship and topological structure. Empirically, we demonstrate and compare the industrial structures of China and the United States, noticing some industries possess totally different ecological niches in different countries. Further, temporal data of flow distances can simulate the evolution of an industry, where our model deductions is proved by empirical evidences.

<div id="pos322"></div>
## Method
We convert the input-output table to an open flow network, called industry flow network(IFN). There are two types of nodes in IFN: one type is the industry node, where a node is an independent sector; the other is the source and the sink node, which represents the external market environment, including final demand and value added respectively. The links in network denote the sale and purchase relationships between producers and consumers within an economy.

For each input-output table, we can convert it to an open flow network with stander weighted adjacency matrix shown in Figure 1, based on which we can define the flow distance calculated by the equation below, which represents the average step that particles in this random system have jumped from i to j for the first time(also called the first-passage flow distance).

<div align="center">
<img src="http://chart.googleapis.com/chart?cht=tx&chl=\l_{i,j} = \frac{(MU^2)_{i,j}}{U_{i,j}}-\frac{(MU^2)_{j,j}}{U_{j,j}}" style="border:none;">
</div>

where the fundamental matrix U are defined as follows:

<div align="center">
<img src="http://chart.googleapis.com/chart?cht=tx&chl=\U= I + M + M^2 + M^3 + \cdots + M^ \infty = (I-M)^{-1}" style="border:none;">
</div>

And the IFN is:
 
<div align="center">
	<img src="/img/project_imgs/ion/Fig_1.png" height="90%" width="90%" />
</div>

<div id="pos323"></div>
## Result
1. Comparison between flow distance and two typical input-output coefficients
Compared with two typical coeiffcients, flow distance captures the information of capital transactions among sectors and structure-based information.

	<div align="center">
		<img src="/img/project_imgs/ion/Fig_2.png" height="90%" width="90%" />
	</div>
2. Comparison of industrial structure between China and the United States
There are common structure between two countries, while some industries possess totally different ecological niches like CompE.

	<div align="center">
		<img src="/img/project_imgs/ion/Fig_3.png" height="90%" width="90%" />
	</div>
3. The evolution of Chinese \textit{Real estate activities} industry as a representative example
We find the trajectory of flow distance can match the development of industrial policy change of the real estate industry during the last decades in China.

	<div align="center">
		<img src="/img/project_imgs/ion/Fig_4.png" height="90%" width="90%" />
	</div>


<hr>


